from dataclasses import dataclass
from typing import Optional, Union, List, Any, Dict

from transformers import PreTrainedTokenizerBase
from transformers.file_utils import PaddingStrategy


@dataclass
class DataCollatorForRDrop:

    tokenizer: PreTrainedTokenizerBase
    padding: Union[bool, str, PaddingStrategy] = True
    max_length: Optional[int] = None
    pad_to_multiple_of: Optional[int] = None

    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:
        batch = self.tokenizer.pad(
            features,
            padding=self.padding,
            max_length=self.max_length,
            pad_to_multiple_of=self.pad_to_multiple_of,
            return_tensors="pt",
        )

        batch = {k: v.reshape(-1).repeat(2) if k == "labels" else v.repeat(2, 1) for k, v in batch.items()}

        if "label" in batch:
            batch["labels"] = batch["label"].reshape(-1).repeat(2)
            del batch["label"]

        return batch
