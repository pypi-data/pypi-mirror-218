from typing import Any

import gymnasium as gym
import numpy as np
from gymnasium.envs.registration import register

from scml.common import intin, make_array
from scml.oneshot.agent import OneShotAgent
from scml.oneshot.awi import OneShotAWI
from scml.oneshot.rl.action import ActionManager
from scml.oneshot.rl.factory import (
    FixedPartnerNumbersOneShotFactory,
    OneShotWorldFactory,
)
from scml.oneshot.rl.observation import ObservationManager
from scml.oneshot.world import SCML2023OneShotWorld

__all__ = ["OneShotEnv"]


class OneShotEnv(gym.Env):
    def __init__(
        self,
        action_manager: ActionManager,
        observation_manager: ObservationManager,
        render_mode=None,
        factory: OneShotWorldFactory = FixedPartnerNumbersOneShotFactory(),
        extra_checks: bool = True,
    ):
        assert action_manager.factory in factory, (
            f"Action Manager is not compatible with the given environment.\n"
            f"Some worlds that can be generated by this environment are not handled"
            f" correctly by this action manager"
        )

        assert observation_manager.factory in factory, (
            f"observation Manager is not compatible with the given environment.\n"
            f"Some worlds that can be generated by this environment are not handled"
            f" correctly by this observation manager"
        )
        self._extra_checks = extra_checks

        agent_type = factory.agent_type
        self._world: SCML2023OneShotWorld = None  # type: ignore
        self._agent_type = agent_type
        self._agent_id: str = ""
        self._agent: OneShotAgent = None  # type: ignore
        self._obs_manager = observation_manager
        self._action_manager = action_manager
        self._factory = factory
        self.action_space = action_manager.make_space()
        self.observation_space = observation_manager.make_space()
        self.render_mode = render_mode
        # self.reset()

    def _get_obs(self):
        return self._obs_manager.encode(self._agent.awi.state)
        # return {"agent": self._agent_location, "target": self._target_location}

    def _get_info(self):
        return dict()
        # return {
        #     "distance": np.linalg.norm(
        #         self._agent_location - self._target_location, ord=1
        #     )
        # }

    def _render_frame(self):
        pass

    def close(self):
        pass

    def render(self):
        pass

    def reset(
        self, *, seed: int | None = None, options: dict[str, Any] | None = None
    ) -> tuple[Any, dict[str, Any]]:
        _ = options
        import random

        random.seed(seed)
        self._world, self._agent = self._factory()
        if self._extra_checks:
            assert self._world in self._factory
        self._agent_id = self._agent.id
        self._world.step_with(dict(), init=True)
        observation = self._get_obs()
        info = self._get_info()

        if self.render_mode == "human":
            self._render_frame()

        return observation, info

    def step(self, action):
        score_before = self._world.scores()[self._agent_id]
        terminated = not self._world.step_with(
            {self._agent_id: self._action_manager.decode(self._agent.awi, action)}  # type: ignore
        )
        if self._world.current_step >= self._world.n_steps - 1:
            terminated = 1
        reward = self._world.scores()[self._agent_id] - score_before
        observation = self._get_obs()
        info = self._get_info()

        if self.render_mode == "human":
            self._render_frame()

        return observation, reward, terminated, False, info


register(
    id="scml/OneShot-v0",
    entry_point="scml.oneshot.rl.env:GridWorldEnv",
    max_episode_steps=None,
)
