{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fad7706-ab2b-4157-a62f-6f6ffc373d61",
   "metadata": {},
   "source": [
    "## Position using DeepLabCut from a Pre-Trained DLC Project\n",
    "\n",
    "**Note: make a copy of this notebook and run the copy to avoid git conflicts in the future**\n",
    "\n",
    "This is a tutorial on how to extract position given a pre-trained DeepLabCut (DLC) model using the Spyglass pipeline used in Loren Frank's lab, UCSF. It will walk through adding your DLC model to Spyglass, executing pose estimation on a novel behavioral video, processing the pose estimation output to extract a centroid and orientation, and inserting the resulting information into the `IntervalPositionInfo` table.<br>\n",
    "-> This tutorial assumes you've completed [tutorial 0](0_intro.ipynb)<br>\n",
    "**Note 2: Make sure you are running this within the spyglass Conda environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f567531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PosixPath, PurePath\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynwb\n",
    "import datajoint as dj\n",
    "import spyglass.common as sgc\n",
    "import spyglass.position.v1 as sgp\n",
    "from spyglass.position import PositionOutput"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e3e1854-0baf-44f4-a5a6-ddc1fdb4c3e1",
   "metadata": {},
   "source": [
    "#### Here is a schematic showing the tables used in this notebook.<br>\n",
    "![dlc_existing.png|2000x900](./../notebook-images/dlc_existing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388fc5f",
   "metadata": {},
   "source": [
    "### Table of Contents<a id='ToC'></a>\n",
    "[`DLCProject`](#DLCProject)<br>\n",
    "[`DLCModel`](#DLCModel)<br>\n",
    "[`DLCPoseEstimation`](#DLCPoseEstimation)<br>\n",
    "[`DLCSmoothInterp`](#DLCSmoothInterp)<br>\n",
    "[`DLCCentroid`](#DLCCentroid)<br>\n",
    "[`DLCOrientation`](#DLCOrientation)<br>\n",
    "[`DLCPos`](#DLCPos)<br>\n",
    "[`DLCPosVideo`](#DLCPosVideo)<br>\n",
    "[`PositionOutput`](#PositionOutput)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc175d",
   "metadata": {},
   "source": [
    "#### [DLCProject](#ToC) <a id='DLCProject'></a>\n",
    "__You can click on any header to return to the Table of Contents__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c51888-b05d-4a51-bb9f-b075db4bbf49",
   "metadata": {},
   "source": [
    "Let us begin with visualizing the contents of the BodyPart table. This table will store standard names of body parts used within DLC models throughout the lab with a concise description.<br>\n",
    ">*Please do not add to this table unless necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.BodyPart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422dd98-728b-4b48-877b-f77c2d60872f",
   "metadata": {},
   "source": [
    "To use an existing DLC project we can use the `insert_existing_project` method on the `DLCProject` table.<br>This function will return a dictionary that can be used to query `DLCProject` in the future and expects:<br>\n",
    ">`project_name`: a short, unique, descriptive name of your project that will be referenced throughout the pipeline<br>`lab_team`: the name of your team from the Spyglass table `LabTeam`<br>`config_path`: string of the path to your existing DLC project's config.yaml<br>`bodyparts`: a list of bodyparts used in your project (optional)<br>`frames_per_video`: number of frames to extract for training from each video (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ecce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"tutorial_DG\"\n",
    "lab_team = \"LorenLab\"\n",
    "project_key = sgp.DLCProject.insert_existing_project(\n",
    "    project_name=project_name,\n",
    "    lab_team=lab_team,\n",
    "    config_path=\"/nimbus/deeplabcut/projects/tutorial_model-LorenLab-2022-07-15/config.yaml\",\n",
    "    bodyparts=[\"redLED_C\", \"greenLED\", \"redLED_L\", \"redLED_R\", \"tailBase\"],\n",
    "    frames_per_video=200,\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d4223-63da-462e-8164-7cc63c945760",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCProject() & {\"project_name\": project_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7876e7",
   "metadata": {},
   "source": [
    "#### [DLCModel](#ToC) <a id='DLCModel'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36a042-f13e-4a36-812a-a4efaeb57a09",
   "metadata": {},
   "source": [
    "Lets take a look at the `DLCModelInput` table next. This table has `dlc_model_name` and `project_name` as primary keys and `project_path` as a secondary key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0a45e-5bd9-48bf-a79d-908bd5a17235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelInput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee99ae-586a-4cbb-9255-15ddd594b1b7",
   "metadata": {},
   "source": [
    "Next we can modify the `project_key` to replace `config_path` with `project_path` to fit with the fields in `DLCModelInput`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc961e93-8fe8-4069-a945-a9fc1e1ad993",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"current project_key:\\n{project_key}\")\n",
    "if not \"project_path\" in project_key:\n",
    "    project_key[\"project_path\"] = os.path.dirname(project_key[\"config_path\"])\n",
    "    del project_key[\"config_path\"]\n",
    "    print(f\"updated project_key:\\n{project_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b958ef7-160c-4141-a7c2-1177fdfd6eb6",
   "metadata": {},
   "source": [
    "Here we can set a unique name for our model using the `dlc_model_name` variable.<br>We then combine this with the updated `project_key` to insert into `DLCModelInput`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49650dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_model_name = \"tutorial_model_DG\"\n",
    "sgp.DLCModelInput().insert1(\n",
    "    {\"dlc_model_name\": dlc_model_name, **project_key}, skip_duplicates=True\n",
    ")\n",
    "sgp.DLCModelInput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c4785-23b4-4a79-9ef9-3815c1215422",
   "metadata": {},
   "source": [
    "Inserting an entry into `DLCModelInput` will also populate `DLCModelSource`. `DLCModelSource` is a table that is used to switch between models trained using Spyglass and pre-existing projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01021925",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelSource() & project_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8756c5-0d85-490b-a712-a95faa074b43",
   "metadata": {},
   "source": [
    "Notice the `source` field in the table above. It will only accept _\"FromImport\"_ or _\"FromUpstream\"_ as entries. Let's checkout the `FromImport` part table attached to `DLCModelSource` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb6d58-225f-49fb-86ee-4b3197aa841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelSource.FromImport() & project_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b9297c-49dc-43b8-ad7b-3897c4d442bf",
   "metadata": {},
   "source": [
    "Next we'll get ready to populate the `DLCModel` table, which holds all the relevant information for both pre-trained models and models trained within Spyglass.<br>First we'll need to determine a set of parameters for our model to select the correct model file.<br>We can visualize a default set below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e01d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelParams.get_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa565b0-37e4-462f-b0d8-fd1b1686b69c",
   "metadata": {},
   "source": [
    "> Here is the syntax to add your own parameter set:\n",
    ">```python\n",
    "dlc_model_params_name = \"make_this_yours\"\n",
    "params = {\n",
    "            \"params\": {},\n",
    "            \"shuffle\": 1,\n",
    "            \"trainingsetindex\": 0,\n",
    "            \"model_prefix\": \"\",\n",
    "        }\n",
    "sgp.DLCModelParams.insert1({\"dlc_model_params_name\": dlc_model_params_name, \"params\": params}, skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581612b4-f4e5-4438-aeeb-f267eaeb5bad",
   "metadata": {},
   "source": [
    "Now let's fetch the primary keys from `DLCModelSource` to make our lives a bit easier when we insert into `DLCModelSelection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b81585-5926-43d3-9e1b-de287ef33826",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model_key = (sgp.DLCModelSource.FromImport() & project_key).fetch1(\"KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb287f-5c3d-431c-b196-5d327e4eb198",
   "metadata": {},
   "source": [
    "And insert into `DLCModelSelection` to allow for population of `DLCModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa23fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModelSelection().insert1(\n",
    "    {**temp_model_key, \"dlc_model_params_name\": \"default\"}, skip_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b3158-a07e-4630-bb42-a609d1d8ee24",
   "metadata": {},
   "source": [
    "Let's populate `DLCModel`!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = (sgp.DLCModelSelection & temp_model_key).fetch1(\"KEY\")\n",
    "sgp.DLCModel.populate(model_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920fc2d-5b81-4d4b-817b-d7549d2810ac",
   "metadata": {},
   "source": [
    "And of course make sure it populated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930df143-c756-4904-b4b6-7eed8c194b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCModel() & model_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db6243",
   "metadata": {},
   "source": [
    "#### [DLCPoseEstimation](#ToC) <a id='DLCPoseEstimation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6873f0e5-d32c-4c06-a964-56f33b5e7c1d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>\n",
    "The following steps should be run on a GPU cluster</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4241c1f-f11a-4701-93cd-bdcc4a437d73",
   "metadata": {},
   "source": [
    "Alright, now that we brought our trained model into Spyglass we're ready to set-up Pose Estimation on a behavioral video of your choice.<br>For this tutorial, you can choose to use an epoch of your choice, we can also use the one specified below. If you'd like to use your own video, just specify the `nwb_file_name` and `epoch` number and make sure it's in the `VideoFile` table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d41790-9643-47e4-a916-df8ee1035059",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwb_file_name = \"J1620210529_.nwb\"\n",
    "epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a295b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgc.VideoFile() & {\"nwb_file_name\": nwb_file_name, \"epoch\": epoch}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420f1fe-56e5-48cb-adb8-09bfc6999d3f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Setting up Pose Estimation</b><br>\n",
    "<code>gputouse</code> determines which GPU core to use for pose estimation. Run the cell below to determine which core has space and set the <code>gputouse</code> variable accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5adf5-9631-4ae5-a91f-e0367ebced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.dlc_utils.get_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc2410-19cb-40d3-b00d-4716e6945be7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Set GPU core here</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1d75f-a4f0-46e7-9726-6e923042a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gputouse = 0  ## 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f7f01-9d06-40ed-91d3-508266888d78",
   "metadata": {},
   "source": [
    "To set up pose estimation, we need to make sure a few things are in order. Using `insert_estimation_task` will take care of these steps for us!<br>Briefly, it will convert out video to be in .mp4 format (DLC struggles with .h264) and determine the directory in which we'll store the pose estimation results.<br>\n",
    ">**`task_mode`** determines whether or not populating `DLCPoseEstimation` runs a new pose estimation, or loads an existing. Use _'trigger'_ unless you've already run this specific pose estimation.<br>**`video_file_num`** will be 0 in almost all cases.<br>**`check_crop`** is a boolean True/False and will trigger a prompt for the user to enter the cropping coordinates. A frame of the video with coordinates will be provided for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21b30f-739d-44f2-aaa0-8401570d2dfb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>When prompted for crop, the behavior takes place on the left-hand maze. The coordinates I used were: <code>50, 500, 50, 800</code>. Feel free to play around with these!</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5913f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_estimation_key = sgp.DLCPoseEstimationSelection.insert_estimation_task(\n",
    "    {\n",
    "        \"nwb_file_name\": nwb_file_name,\n",
    "        \"epoch\": epoch,\n",
    "        \"video_file_num\": 0,\n",
    "        **model_key,\n",
    "    },\n",
    "    task_mode=\"trigger\",\n",
    "    params={\"gputouse\": gputouse, \"videotype\": \"mp4\", \"cropping\": None},\n",
    "    check_crop=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0b2dc-5a57-45d7-94e6-44b0d08554de",
   "metadata": {},
   "source": [
    "And now we populate `DLCPoseEstimation`! This might take a bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c30671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPoseEstimation().populate(pose_estimation_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede348f-c6fe-4861-b51f-e41143653673",
   "metadata": {},
   "source": [
    "Let's visualize the output from Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb089d35-3d59-403b-b802-242ed4513acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(sgp.DLCPoseEstimation() & pose_estimation_key).fetch_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b35927",
   "metadata": {},
   "source": [
    "#### [DLCSmoothInterp](#ToC) <a id='DLCSmoothInterp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ca70f-2ce6-435c-bb21-93ebcbba370e",
   "metadata": {},
   "source": [
    "Now that we've completed pose estimation, it's time to identify NaNs and optionally interpolate over low likelihood periods and smooth the resulting positions.<br>First we need to define some parameters for smoothing and interpolation. We can see the default parameter set below.<br>__Note__: it is recommended to use the `just_nan` parameters here and save interpolation and smoothing for the centroid step as this provides for a better end result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079c861-45f3-4428-9d9a-0a299254ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default parameter set to interpolate and smooth over each LED individually\n",
    "print(sgp.DLCSmoothInterpParams.get_default())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5caf1e8-fb00-4193-8b52-bc69c9a00ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The just_nan parameter set that identifies NaN indices and leaves smoothing and interpolation to the centroid step\n",
    "print(sgp.DLCSmoothInterpParams.get_nan_params())\n",
    "si_params_name = \"just_nan\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c25d7-9cb8-4307-90d9-be5c3b78cfd0",
   "metadata": {},
   "source": [
    "> If you'd like to change any of these parameters, here is the syntax to do that\n",
    ">```python\n",
    "si_params_name = 'your_unique_param_name'\n",
    "params = {\n",
    "    \"smoothing_params\": {\n",
    "        \"smoothing_duration\": 0.##,\n",
    "        \"smooth_method\": \"moving_avg\",\n",
    "    },\n",
    "    \"interp_params\": {\n",
    "        \"likelihood_thresh\": 0.##,\n",
    "    },\n",
    "    \"max_plausible_speed\": ###,\n",
    "    \"speed_smoothing_std_dev\": 0.###,\n",
    "}\n",
    "sgp.DLCSmoothInterpParams().insert1(\n",
    "    {\n",
    "        'dlc_si_params_name': si_params_name,\n",
    "        \"params\": params,\n",
    "    },\n",
    "    skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95887e-71ff-4212-b0f6-bc90fb7dcb96",
   "metadata": {},
   "source": [
    "Here we'll create a dictionary with the correct set of keys for the `DLCSmoothInterpSelection` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "si_key = pose_estimation_key.copy()\n",
    "fields = list(sgp.DLCSmoothInterpSelection.fetch().dtype.fields.keys())\n",
    "si_key = {key: val for key, val in si_key.items() if key in fields}\n",
    "si_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235561b-5c29-41d5-9bbb-b2a95a497dfe",
   "metadata": {},
   "source": [
    "And now we can insert all of the bodyparts we want to process into `DLCSmoothInterpSelection`<br>\n",
    "First lets visualize the bodyparts we have available to us.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f987d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((sgp.DLCPoseEstimation.BodyPart & pose_estimation_key).fetch(\"bodypart\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2520750-94ca-45c3-a841-15bb04d896d7",
   "metadata": {},
   "source": [
    "We can use `insert1` to insert a single bodypart, but would suggest using `insert` to insert a list of keys with different bodyparts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0beab3d-690c-47b8-9763-3adcfbd9538f",
   "metadata": {},
   "source": [
    ">_Syntax to insert a single bodypart_\n",
    ">```python\n",
    "sgp.DLCSmoothInterpSelection.insert1(\n",
    "    {\n",
    "        **si_key,\n",
    "        'bodypart': 'greenLED',\n",
    "        'dlc_si_params_name': si_params_name,\n",
    "    },\n",
    "    skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88869472-c2a5-45a6-997f-a3d05d262759",
   "metadata": {},
   "source": [
    "Lets set a list of bodyparts we want to insert and then insert them into `DLCSmoothInterpSelection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyparts = [\"greenLED\", \"redLED_C\"]\n",
    "sgp.DLCSmoothInterpSelection.insert(\n",
    "    [\n",
    "        {\n",
    "            **si_key,\n",
    "            \"bodypart\": bodypart,\n",
    "            \"dlc_si_params_name\": si_params_name,\n",
    "        }\n",
    "        for bodypart in bodyparts\n",
    "    ],\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3527cd1",
   "metadata": {},
   "source": [
    "And to make sure that all of the bodyparts we want made it into the the selection table, we can visualize the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a35e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCSmoothInterpSelection() & si_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ccae76-b58c-4239-82fd-361b16327b28",
   "metadata": {},
   "source": [
    "Now we can populate `DLCSmoothInterp`, which will perform smoothing and interpolation on all of the bodyparts we specified.<br>We can limit the populate using `si_key` since it is bodypart agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCSmoothInterp().populate(si_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80805fdd-9867-4784-81d1-887f44ee3ccf",
   "metadata": {},
   "source": [
    "And let's visualize the resulting position data using a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sgp.DLCSmoothInterp() & {**si_key, \"bodypart\": bodyparts[0]}\n",
    ").fetch1_dataframe().plot.scatter(x=\"x\", y=\"y\", s=1, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5bb2c-b168-4d31-83b6-1d81775415e2",
   "metadata": {},
   "source": [
    "#### [DLCSmoothInterpCohort](#ToC) <a id='DLCSmoothInterpCohort'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629eb32-fbc6-4828-92b7-d15d5788158e",
   "metadata": {},
   "source": [
    "Now that we've smoothed and interpolated our position data for each bodypart, we need to form a set of bodyparts from which we want to derive a centroid and orientation (or potentially a second set for orientation). This is the goal of the `DLCSmoothInterpCohort` table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ab7da-337f-40f6-8c2a-e38c226fabde",
   "metadata": {},
   "source": [
    "First, let's make a key that represents the 'cohort' we want to form.\n",
    "> We'll set the `dlc_si_cohort_selection_name` to a concise name<br>We'll also form a dictionary with the bodypart name as the key and the smoothing/interpolation parameter name used for that bodypart as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfab362",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_key = si_key.copy()\n",
    "if \"bodypart\" in cohort_key:\n",
    "    del cohort_key[\"bodypart\"]\n",
    "if \"dlc_si_params_name\" in cohort_key:\n",
    "    del cohort_key[\"dlc_si_params_name\"]\n",
    "cohort_key[\"dlc_si_cohort_selection_name\"] = \"green_red_led\"\n",
    "cohort_key[\"bodyparts_params_dict\"] = {\n",
    "    \"greenLED\": si_params_name,\n",
    "    \"redLED_C\": si_params_name,\n",
    "}\n",
    "print(cohort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646b4a5-16b9-48d5-ae44-2b57c220062f",
   "metadata": {},
   "source": [
    "Here we'll insert the cohort into the `DLCSmoothInterpCohortSelection` table<br>..and populate `DLCSmoothInterpCohort`, which collates the separately smoothed and interpolated bodyparts into a single entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9356875",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCSmoothInterpCohortSelection().insert1(cohort_key, skip_duplicates=True)\n",
    "sgp.DLCSmoothInterpCohort.populate(cohort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e952ff54-dbc2-4cf5-88c4-55eb8eb578e7",
   "metadata": {},
   "source": [
    "And of course, let's make sure that the table populated correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5aa8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCSmoothInterpCohort.BodyPart() & cohort_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8332f",
   "metadata": {},
   "source": [
    "#### [DLCCentroid](#ToC) <a id='DLCCentroid'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0b2e2-e2f7-475f-ae9e-8a9c134881f1",
   "metadata": {},
   "source": [
    "We now have a cohort of smoothed and interpolated bodyparts from which to determine a centroid!<br>To start, we'll need a set of parameters to use for determining the centroid. For this tutorial, we can use the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ae5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the default set\n",
    "print(sgp.DLCCentroidParams.get_default())\n",
    "centroid_params_name = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b45da-59da-46f0-aae2-c05c9b88ec39",
   "metadata": {},
   "source": [
    ">Here is the syntax to add your own parameters:\n",
    ">```python\n",
    "centroid_params = {\n",
    "    'centroid_method': 'two_pt_centroid',\n",
    "    'points' : {\n",
    "        'point1': 'greenLED',\n",
    "        'point2': 'redLED_C',},\n",
    "    'speed_smoothing_std_dev': 0.100,\n",
    "}\n",
    "centroid_params_name = 'your_unique_param_name'\n",
    "sgp.DLCCentroidParams.insert1({'dlc_centroid_params_name': centroid_params_name,\n",
    "                                'params': centroid_params},\n",
    "                                skip_duplicates=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683fc3b-e63b-4ba9-ab5a-8227f0a64feb",
   "metadata": {},
   "source": [
    "And now let's make a key to insert into `DLCCentroidSelection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_key = cohort_key.copy()\n",
    "fields = list(sgp.DLCCentroidSelection.fetch().dtype.fields.keys())\n",
    "centroid_key = {key: val for key, val in centroid_key.items() if key in fields}\n",
    "centroid_key[\"dlc_centroid_params_name\"] = centroid_params_name\n",
    "print(centroid_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf3415-4f8e-456a-92aa-6a22aa33edee",
   "metadata": {},
   "source": [
    "Let's insert it into `DLCCentroidSelection` and then populate `DLCCentroid` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b59e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCCentroidSelection.insert1(centroid_key, skip_duplicates=True)\n",
    "sgp.DLCCentroid.populate(centroid_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad2907-3791-49c5-911c-b394da20861b",
   "metadata": {},
   "source": [
    "Here we can visualize the resulting centroid position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a487ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCCentroid() & centroid_key).fetch1_dataframe().plot.scatter(\n",
    "    x=\"position_x\",\n",
    "    y=\"position_y\",\n",
    "    c=\"speed\",\n",
    "    colormap=\"viridis\",\n",
    "    alpha=0.5,\n",
    "    s=0.5,\n",
    "    figsize=(10, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2b462",
   "metadata": {},
   "source": [
    "#### [DLCOrientation](#ToC) <a id='DLCOrientation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe9e8a-4805-4916-818d-393ae14d5151",
   "metadata": {},
   "source": [
    "We'll now go through a similar process to identify the orientation!<br>To start, we'll need a set of parameters to use for determining the orientation. For this tutorial, we can use the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74efceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sgp.DLCOrientationParams.get_default())\n",
    "dlc_orientation_params_name = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b2d925-a749-45a8-9b79-8c0935021f88",
   "metadata": {},
   "source": [
    "Here we'll prune the `cohort_key` we used above and add our `dlc_orientation_params_name` to make it suitable for `DLCOrientationSelection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedfd230",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = list(sgp.DLCOrientationSelection.fetch().dtype.fields.keys())\n",
    "orient_key = {key: val for key, val in cohort_key.items() if key in fields}\n",
    "orient_key[\"dlc_orientation_params_name\"] = dlc_orientation_params_name\n",
    "print(orient_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4defcf-a4ab-4d87-9183-803776f5eefd",
   "metadata": {},
   "source": [
    "And now let's insert into `DLCOrientationSelection` and populate `DLCOrientation` to determine the orientation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56793200",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCOrientationSelection().insert1(orient_key, skip_duplicates=True)\n",
    "sgp.DLCOrientation().populate(orient_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170037c-ce84-4241-bcd7-1b2eb7100615",
   "metadata": {},
   "source": [
    "We can fetch the output of `DLCOrientation` as a dataframe to make sure everything looks appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c972e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCOrientation() & orient_key).fetch1_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c4b409",
   "metadata": {},
   "source": [
    "#### [DLCPos](#ToC) <a id='DLCPos'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57bf28e-cc74-4254-84a8-5a6a52d0b559",
   "metadata": {},
   "source": [
    "Ok, we're now done with processing the position data! We just have to do some table manipulations to make sure everything ends up in the same format and same location.<br>\n",
    "To summarize, we brought in a pretrained DLC project, used that model to run pose estimation on a new behavioral video, smoothed and interpolated the result, formed a cohort of bodyparts, and determined the centroid and orientation of this cohort. **_Whew!_**<br>\n",
    "Now let's populate `DLCPos` with our centroid and orientation entries from above.<br>----<br>\n",
    "To begin, we'll make a key that combines the cohort names we used for the orientation and centroid as well as the params names for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947afa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = list(sgp.DLCPosV1.fetch().dtype.fields.keys())\n",
    "dlc_key = {key: val for key, val in centroid_key.items() if key in fields}\n",
    "dlc_key[\"dlc_si_cohort_centroid\"] = centroid_key[\"dlc_si_cohort_selection_name\"]\n",
    "dlc_key[\"dlc_si_cohort_orientation\"] = orient_key[\n",
    "    \"dlc_si_cohort_selection_name\"\n",
    "]\n",
    "dlc_key[\"dlc_orientation_params_name\"] = orient_key[\n",
    "    \"dlc_orientation_params_name\"\n",
    "]\n",
    "print(dlc_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b8f581-e87e-40f3-8eb0-0cb8ac79a425",
   "metadata": {},
   "source": [
    "Now we can insert into `DLCPosSelection` and populate `DLCPos` with our `dlc_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7cb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPosSelection().insert1(dlc_key, skip_duplicates=True)\n",
    "sgp.DLCPosV1().populate(dlc_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13444ea-ea60-4fe8-9ebe-332299122844",
   "metadata": {},
   "source": [
    "We can also make sure that all of our data made it through by fetching the dataframe attached to this entry.<br>We should expect 8 columns:\n",
    ">time<br>video_frame_ind<br>position_x<br>position_y<br>orientation<br>velocity_x<br>velocity_y<br>speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCPosV1() & dlc_key).fetch1_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede5081-0506-4bfb-8b3c-88cef1de9f99",
   "metadata": {},
   "source": [
    "And even more, we can fetch the `pose_eval_result` that is calculated during this step. This field contains the percentage of frames that each bodypart was below the likelihood threshold of 0.95 as a means of assessing the quality of the pose estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6910c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgp.DLCPosV1() & dlc_key).fetch1(\"pose_eval_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba851a47",
   "metadata": {},
   "source": [
    "#### [DLCPosVideo](#ToC) <a id='DLCPosVideo'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbeaced-7a63-4730-bf0e-810b66d2f7e4",
   "metadata": {},
   "source": [
    "Here we can create a video with the centroid and orientation overlaid on the animal's behavioral video. This will also plot the likelihood of each bodypart used in the cohort. This is completely optional, but a good idea to make sure everything looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPosVideoParams.insert_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"percent_frames\": 0.05,\n",
    "    \"incl_likelihood\": True,\n",
    "}\n",
    "sgp.DLCPosVideoParams.insert1(\n",
    "    {\"dlc_pos_video_params_name\": \"five_percent\", \"params\": params},\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPosVideoSelection.insert1(\n",
    "    {**dlc_key, \"dlc_pos_video_params_name\": \"five_percent\"},\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aee96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.DLCPosVideo().populate(dlc_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ce032",
   "metadata": {},
   "source": [
    "#### [PositionOutput](#ToC) <a id='PositionOutput'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5003cb7-a0ef-445e-8c9f-a2342f2cda13",
   "metadata": {},
   "source": [
    "`PositionOutput` is the final table of the position pipeline and is automatically populated when we populate `DLCPos`! Let's make sure that our entry made it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PositionOutput() & dlc_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74d710-4137-41b0-90ed-6231d36f6e09",
   "metadata": {},
   "source": [
    "`PositionOutput` also has a part table, similar to the `DLCModelSource` table above. Let's check that out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca3928-f51e-480f-94de-f22956017931",
   "metadata": {},
   "outputs": [],
   "source": [
    "PositionOutput.DLCPosV1() & dlc_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acfbf12-d69c-4412-ab18-6da7f31dd9e8",
   "metadata": {},
   "source": [
    "#### [PositionVideo](#ToC)<a id='PositionVideo'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3bf99a-9c29-47f0-a743-0f1217a51b72",
   "metadata": {},
   "source": [
    "Bonus points if you made it this far... We can use the `PositionVideo` table to create a video that overlays just the centroid and orientation (regardless of upstream source) on the behavioral video. This table uses the parameter `plot` to determine whether to plot the entry deriving from the DLC arm or from the Trodes arm of the position pipeline. This parameter also accepts 'all', which will plot both (if they exist) in order to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.PositionVideoSelection().insert1(\n",
    "    {\n",
    "        \"nwb_file_name\": \"J1620210604_.nwb\",\n",
    "        \"interval_list_name\": \"pos 13 valid times\",\n",
    "        \"trodes_position_id\": 0,\n",
    "        \"dlc_position_id\": 1,\n",
    "        \"plot\": \"DLC\",\n",
    "        \"output_dir\": \"/home/dgramling/Src/\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp.PositionVideo.populate({\"plot\": \"DLC\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f9d5b-4fbf-4831-b275-46e4051ecc09",
   "metadata": {},
   "source": [
    "### _CONGRATULATIONS!!_\n",
    "Please treat yourself to a nice tea break :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb3e99",
   "metadata": {},
   "source": [
    "### [`Return To Table of Contents`](#ToC)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spyglass-position] *",
   "language": "python",
   "name": "conda-env-spyglass-position-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
